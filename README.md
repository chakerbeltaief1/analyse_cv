# ğŸ§  Analyse et Classification Intelligente de DonnÃ©es Ã  partir de CV

Ce projet a pour objectif de traiter automatiquement des CV au format PDF, dâ€™en extraire les informations clÃ©s (entitÃ©s) grÃ¢ce Ã  des techniques avancÃ©es de NLP (Natural Language Processing), puis de classifier le profil Ã  lâ€™aide du Machine Learning (Random Forest)


## ğŸ”„ SchÃ©ma Global du Pipeline

graph TD;
    A[ğŸ“„ PDF/CV] --> B[ğŸ” Extraction texte]
    B --> C[ğŸ§¹ PrÃ©traitement NLP]
    C --> D[ğŸ§  Extraction d'entitÃ©s NER]
    D --> E[ğŸ“Š Vectorisation TF-IDF]
    E --> F[ğŸ¤– Classification ML(Random Forest)]
    F --> G[ğŸ“Œ Profil classifiÃ© + DonnÃ©es structurÃ©es]
    G --> H[ğŸ“Š Interface Streamlit]
    

## ğŸ§© DÃ©tail des Ã‰tapes

### ğŸ“„ 1. PDF CV
- Point de dÃ©part du pipeline : le CV peut Ãªtre un pdf.

### ğŸ” 2. Extraction de texte
- Utilisation de bibliothÃ¨ques telles que **PyMuPDF**, **PDFMiner** .
- Extraction du contenu brut (texte) du CV.

### ğŸ§¹ 3. Nettoyage + NLP
- Traitement linguistique :
  - Suppression des caractÃ¨res spÃ©ciaux
  - Tokenisation
  - Mise en minuscule
  - Suppression des *stopwords*
  - Lemmatisation / Stemmatisation

### ğŸ§  4. Extraction d'entitÃ©s (NER)
- Utilisation de modÃ¨les NLP avec **spaCy(fr et en)** .
- Extraction automatique de :
  - Nom & PrÃ©nom
  - Email, numÃ©ro de tÃ©lÃ©phone
  - linkedin ,github .......
  - localisation
  - education & expÃ©riences professionnelles & projets & skills & languages

### ğŸ“Š 5. Vectorisation TF-IDF
- Transformation du texte nettoyÃ© en vecteurs numÃ©riques avec **TF-IDF**.
- Permet de reprÃ©senter lâ€™importance relative des termes par rapport Ã  lâ€™ensemble des documents.

### ğŸ¤– 6. Classification via Machine Learning
- EntraÃ®nement dâ€™un modÃ¨le **Random Forest Classifier**.
- Objectif : prÃ©dire automatiquement le type de profil (ex de dataset :  *Data Engineer*, *web developer*,HR electrical CONSULTANT ...etc.).
- ProbabilitÃ©s associÃ©es Ã  chaque catÃ©gorie pour une analyse nuancÃ©e


### ğŸ“Œ 7. RÃ©sultat final
- GÃ©nÃ©ration dâ€™un **profil classifiÃ©**
- Liste structurÃ©e des **entitÃ©s extraites** (nom, email, compÃ©tencesâ€¦etc)
## ğŸ› ï¸ Technologies utilisÃ©es

- **Backend** :
  - Python 3.10.0
  - Flask (API Flask)
  - spaCy (NLP)
  - Random Foreset (ML)
  - PyMuPDF/PDFMiner (extraction PDF)
  - python-docx (extraction DOCX)


---

## ğŸ’» Interface Utilisateur avec Streamlit

Un fichier `streamlit_app.py` est inclus pour permettre aux utilisateurs dâ€™interagir avec le modÃ¨le via une interface simple et intuitive.

### FonctionnalitÃ©s :
- ğŸ“¤ Upload dâ€™un CV au format PDF
- ğŸ” Affichage du texte extrait et des entitÃ©s dÃ©tectÃ©es
- ğŸ§  Classification automatique du profil
- ğŸ§¾ RÃ©sumÃ© structurÃ© prÃªt Ã  Ãªtre exportÃ©

### Lancement :
```bash
streamlit run streamlit_app.py
## ğŸ› ï¸ Technologies utilisÃ©es
- **Frontend** :
  - Streamlit
  - Plotly
  - Matplotlib
  - Pandas
## ğŸ“¦ Installation

### PrÃ©requis
- Python 3.10.0
- pip

### Installation des dÃ©pendances

```bash
cd cv-analyzer
# CrÃ©er un environnement virtuel
python -m venv venv
# Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger les modÃ¨les spaCy
python -m spacy download fr_core_news_lg
python -m spacy download en_core_web_lg
```

## ğŸš€ Utilisation

### DÃ©marrer l'API Backend

```bash
cd backend
python app.py
```

L'API sera accessible Ã  l'adresse `http://localhost:5000`

### Lancer l'interface Streamlit

```bash
cd frontend
streamlit run streamlit_app.py
```

L'interface sera disponible Ã  l'adresse `http://localhost:8501`
 
 ğŸ‘¨â€ğŸ’»  Projet crÃ©Ã© par Chaker Beltaief 

